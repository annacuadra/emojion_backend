{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90d03ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentiment_model.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "\n",
    "dataset = pd.read_csv('sentiment\\sentiment_data.csv', encoding='ISO-8859-1')\n",
    "stemmer = pd.read_csv('datasets\\stem_tl.csv')\n",
    "word_to_stem = dict(zip(stemmer['word'], stemmer['stem']))\n",
    "\n",
    "replace_patterns = {\n",
    "    re.compile(r\"\\bngayo\\'y\\b\"): 'ngayon ay',\n",
    "    re.compile(r\"\\bhangga\\'t\\b\"): 'hanggang',\n",
    "    re.compile(r\"\\b\\'?y\\b\"): ' ay',\n",
    "    re.compile(r\"\\b\\'?t\\b\"): ' at',\n",
    "    re.compile(r\"\\b\\'?yan\\b\"): 'iyan',\n",
    "    re.compile(r\"\\b\\'?yo\\b\"): 'iyo',\n",
    "    re.compile(r\"\\b\\'?yon\\b\"): 'iyon',\n",
    "    re.compile(r\"\\b\\'?yun\\b\"): 'iyun',\n",
    "    re.compile(r\"\\b\\'?pagkat\\b\"): 'sapagkat',\n",
    "    re.compile(r\"\\b\\'?di\\b\"): 'hindi',\n",
    "    re.compile(r\"\\b\\'?kaw\\b\"): \"ikaw\",\n",
    "    re.compile(r\"\\b\\'?to\\b\"): 'ito',\n",
    "    re.compile(r\"\\b\\'?wag\\b\"): 'huwag',\n",
    "    re.compile(r\"\\bgano\\'n\\b\"): 'ganoon'\n",
    "}\n",
    "\n",
    "def data_preprocess(text, replace_patterns, word_to_stem):\n",
    "    text = text.lower()\n",
    "\n",
    "    for pattern, replacement in replace_patterns.items():\n",
    "        text = pattern.sub(replacement, text)\n",
    "\n",
    "    text = re.sub(\"[^a-zA-Z0-9\\s?!.]\", '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    text = ' '.join([word_to_stem.get(word, word) for word in tokens])\n",
    "\n",
    "    return text\n",
    "\n",
    "dataset['text_preprocessed'] = dataset['text'].apply(data_preprocess, replace_patterns=replace_patterns, word_to_stem=word_to_stem)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "X = dataset['text_preprocessed']\n",
    "y = dataset['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_test_counts = vectorizer.transform(X_test)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "svm_clf = SVC(kernel='linear')\n",
    "svm_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "joblib.dump((svm_clf, vectorizer, tfidf_transformer), 'sentiment_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0e7e4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a text: sada\n",
      "Error: The system currently only accepts Tagalog words.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "from langdetect import detect\n",
    "\n",
    "model_components = joblib.load('sentiment_model.pkl')\n",
    "SVM_model, vectorizer, tfidf_transformer = model_components\n",
    "\n",
    "stemmer = pd.read_csv('datasets\\stem_tl.csv')\n",
    "word_to_stem = dict(zip(stemmer['word'], stemmer['stem']))\n",
    "\n",
    "replace_patterns = {\n",
    "    re.compile(r\"\\bngayo\\'y\\b\"): 'ngayon ay',\n",
    "    re.compile(r\"\\bhangga\\'t\\b\"): 'hanggang',\n",
    "    re.compile(r\"\\b\\'?y\\b\"): ' ay',\n",
    "    re.compile(r\"\\b\\'?t\\b\"): ' at',\n",
    "    re.compile(r\"\\b\\'?yan\\b\"): 'iyan',\n",
    "    re.compile(r\"\\b\\'?yo\\b\"): 'iyo',\n",
    "    re.compile(r\"\\b\\'?yon\\b\"): 'iyon',\n",
    "    re.compile(r\"\\b\\'?yun\\b\"): 'iyun',\n",
    "    re.compile(r\"\\b\\'?pagkat\\b\"): 'sapagkat',\n",
    "    re.compile(r\"\\b\\'?di\\b\"): 'hindi',\n",
    "    re.compile(r\"\\b\\'?kaw\\b\"): \"ikaw\",\n",
    "    re.compile(r\"\\b\\'?to\\b\"): 'ito',\n",
    "    re.compile(r\"\\b\\'?wag\\b\"): 'huwag',\n",
    "    re.compile(r\"\\bgano\\'n\\b\"): 'ganoon'\n",
    "}\n",
    "\n",
    "foul_words = {\n",
    "    'gago','gaga', 'puta', 'pakyu','pakshet','buang','walanghiya ','piste','lintik',\n",
    "    'putangina','tarantado','punyeta','bwisit','kupal','hinyupak', 'tanga', 'tangina','bobo','boba','putragis', 'syet'\n",
    "}\n",
    "\n",
    "class_names = {\n",
    "    1: 'fear',\n",
    "    2: 'anger',\n",
    "    3: 'joy',\n",
    "    4: 'sadness',\n",
    "    5: 'disgust',\n",
    "    6: 'surprise'\n",
    "}\n",
    "\n",
    "def data_preprocess(text, replace_patterns, word_to_stem):\n",
    "    text = text.lower()\n",
    "\n",
    "    for pattern, replacement in replace_patterns.items():\n",
    "        text = pattern.sub(replacement, text)\n",
    "\n",
    "    text = re.sub(\"[^a-zA-Z0-9\\s?!.]\", '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    text = ' '.join([word_to_stem.get(word, word) for word in tokens])\n",
    "\n",
    "    return text\n",
    "\n",
    "user_input = input(\"Enter a text: \")\n",
    "\n",
    "try:\n",
    "    lang = detect(user_input)\n",
    "except Exception as e:\n",
    "    lang = None\n",
    "\n",
    "if lang.lower() != 'tl':\n",
    "    print(\"Error: The system currently only accepts Tagalog words.\")\n",
    "else:\n",
    "    if any(word in user_input.lower() for word in foul_words):\n",
    "        print(\"Warning: There are words that are not appropriate for children to read.\")\n",
    "    else:\n",
    "        user_input_processed = data_preprocess(user_input, replace_patterns, word_to_stem)\n",
    "\n",
    "        user_input_vectorized = vectorizer.transform([user_input_processed])\n",
    "        user_input_tfidf = tfidf_transformer.transform(user_input_vectorized)\n",
    "\n",
    "        decision_values = SVM_model.decision_function(user_input_tfidf)[0]\n",
    "\n",
    "        exp_values = np.exp(decision_values - np.max(decision_values))  \n",
    "        probabilities = exp_values / exp_values.sum(axis=0, keepdims=True)\n",
    "\n",
    "        emotion_probabilities_dict = {class_names[i+1]: probability * 100 for i, probability in enumerate(probabilities)}\n",
    "\n",
    "        for emotion in class_names.values():\n",
    "            if emotion not in emotion_probabilities_dict:\n",
    "                emotion_probabilities_dict[emotion] = 0.0\n",
    "\n",
    "        print(\"\\nEmotion probabilities:\")\n",
    "        for emotion, percentage in emotion_probabilities_dict.items():\n",
    "            print(f\"{emotion}: {percentage:.2f}%\")\n",
    "\n",
    "        max_emotion = max(emotion_probabilities_dict, key=emotion_probabilities_dict.get)\n",
    "\n",
    "        print(f\"\\nThe predicted emotion for the input text is: {max_emotion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7633ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
