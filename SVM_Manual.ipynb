{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0269d9b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6290322580645161\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.73      0.55      0.63        20\n",
      "       anger       0.59      0.48      0.53        21\n",
      "         joy       0.74      0.67      0.70        21\n",
      "     sadness       0.80      0.38      0.52        21\n",
      "     disgust       0.83      0.75      0.79        20\n",
      "    surprise       0.44      0.95      0.61        21\n",
      "\n",
      "    accuracy                           0.63       124\n",
      "   macro avg       0.69      0.63      0.63       124\n",
      "weighted avg       0.69      0.63      0.63       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "dataset = pd.read_csv('datasets\\story_emotion3.csv')\n",
    "\n",
    "stopword = pd.read_csv('datasets\\stopwords_tl.csv')\n",
    "stopwords_set = set(stopword['stopword'])\n",
    "\n",
    "stemmer = pd.read_csv('datasets\\stem_tl.csv')\n",
    "word_to_stem = dict(zip(stemmer['word'], stemmer['stem']))\n",
    "\n",
    "replace_patterns = {\n",
    "    re.compile(r\"\\bngayo\\'y\\b\"): 'ngayon ay',\n",
    "    re.compile(r\"\\bhangga\\'t\\b\"): 'hanggang',\n",
    "    re.compile(r\"\\b\\'?y\\b\"): ' ay',\n",
    "    re.compile(r\"\\b\\'?t\\b\"): ' at',\n",
    "    re.compile(r\"\\b\\'?yan\\b\"): 'iyan',\n",
    "    re.compile(r\"\\b\\'?yo\\b\"): 'iyo',\n",
    "    re.compile(r\"\\b\\'?yon\\b\"): 'iyon',\n",
    "    re.compile(r\"\\b\\'?yun\\b\"): 'iyun',\n",
    "    re.compile(r\"\\b\\'?pagkat\\b\"): 'sapagkat',\n",
    "    re.compile(r\"\\b\\'?di\\b\"): 'hindi',\n",
    "    re.compile(r\"\\b\\'?kaw\\b\"): \"ikaw\",\n",
    "    re.compile(r\"\\b\\'?to\\b\"): 'ito',\n",
    "    re.compile(r\"\\b\\'?wag\\b\"): 'huwag',\n",
    "    re.compile(r\"\\bgano\\'n\\b\"): 'ganoon'\n",
    "}\n",
    "\n",
    "class_names = {\n",
    "    1: 'fear',\n",
    "    2: 'anger',\n",
    "    3: 'joy',\n",
    "    4: 'sadness',\n",
    "    5: 'disgust',\n",
    "    6: 'surprise'\n",
    "}\n",
    "def data_preprocess(text, replace_patterns, word_to_stem, stopwords_set):\n",
    "    text = text.lower()\n",
    "\n",
    "    for pattern, replacement in replace_patterns.items():\n",
    "        text = pattern.sub(replacement, text)\n",
    "\n",
    "    text = re.sub(\"[^a-zA-Z0-9\\s?!]\", '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    text = ' '.join([word_to_stem.get(word, word) for word in tokens if word.lower() not in stopwords_set])\n",
    "\n",
    "    return text\n",
    "\n",
    "dataset['text_preprocessed'] = dataset['text'].apply(data_preprocess, replace_patterns=replace_patterns, word_to_stem=word_to_stem, stopwords_set=stopwords_set)\n",
    "\n",
    "class MulticlassSVM:\n",
    "    def __init__(self, learning_rate=0.01, num_epochs=5, C=1.0):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.C = C\n",
    "        self.classes = None\n",
    "        self.classifiers = {}\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        self.classes = np.unique(Y)\n",
    "\n",
    "        for i, class_label in enumerate(self.classes):\n",
    "            binary_labels = np.where(Y == class_label, 1, -1)\n",
    "            weights, bias = self._train_one_vs_rest(X, binary_labels)\n",
    "            self.classifiers[class_label] = {\"weights\": weights, \"bias\": bias}\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros((X.shape[0], len(self.classes)))\n",
    "\n",
    "        for i, class_label in enumerate(self.classes):\n",
    "            weights = self.classifiers[class_label][\"weights\"]\n",
    "            bias = self.classifiers[class_label][\"bias\"]\n",
    "            predictions[:, i] = np.dot(X, weights) + bias\n",
    "\n",
    "        predicted_labels = self.classes[np.argmax(predictions, axis=1)]\n",
    "\n",
    "        return predicted_labels\n",
    "\n",
    "    def _train_one_vs_rest(self, X, binary_labels):\n",
    "        num_samples, num_features = X.shape\n",
    "        weights = np.zeros(num_features)\n",
    "        bias = 0\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            for i in range(num_samples):\n",
    "                if binary_labels[i] * (np.dot(X[i], weights) + bias) < 1:\n",
    "                    weights = weights + self.learning_rate * (\n",
    "                        binary_labels[i] * X[i] - 2 * self.C * weights\n",
    "                    )\n",
    "                    bias = bias + self.learning_rate * binary_labels[i]\n",
    "\n",
    "        return weights, bias\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "X = dataset['text']\n",
    "Y = dataset['emotion']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_vectorized)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_vectorized)\n",
    "\n",
    "# Create an instance of the MulticlassSVM classifier\n",
    "svm_classifier = MulticlassSVM(C=0.1)\n",
    "\n",
    "# Fit the classifier on the training data\n",
    "svm_classifier.fit(X_train_tfidf.toarray(), Y_train.values)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "Y_pred = svm_classifier.predict(X_test_tfidf.toarray())\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(Y_test, Y_pred, target_names=class_names.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6e5ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
